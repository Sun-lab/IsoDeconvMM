---
title: "IsoDeconvMM Pipeline"
author: "Hillary Heiling"
date: "October 16, 2019"
output: html_document
---

## Items needed before Step 0:

* .bam files of mixture and pure samples (not .bai)
* Cuffdiff output

## Original Process: Before GeneModel_Build.R file and corresponding processes

*Step 0.1*: step1_check_and_filter.R

Input: .bam files - mixed and pure sample files, or pure samples only?

Based on FragLenths_Function_mixture.R, probably just the pure samples need to go through this process.

Output: "_sorted_by_name_uniq_filterd.bam" files (_count/ folder in Doug's code)

*Step 0.2*: step2_read_depth.R

Diagnostics only. Optional?

Input: "count_ ... .txt" files from Step 0.1

Output: Summary plot (pdf)

*Step 0.3*: step3_countReads.R

Inputs: .bed file, all "_sorted_by_name_unique_filtered.bam" files from Step 0.1

Output: "_counts.txt" file from countReads() function from `isoform` library

*Step 0.4*: step4_summarize_counts.r

Inputs: 

* Some .RData object (Homo_sapiens.GRCh37.66.nTE.RData, or its equivalent)
* The "_counts.txt" files from step 0.3

Output: A dataset with the gene counts matrix with file name "gene_counts_%d_%d.txt"

Thoughts: Since I haven't seen where the gene_counts_..._.txt files are used, perhaps this is optional for the overall process and is instead only used for diagnostic purposes?

*Step 0.5*: FragLengths_Function_mixutre.R

Inputs: Mixture .bam files, pure sample reference "_sorted_by_name_unique_filtered.bam" files from Step 0.1.

Process: Create combinations of files where there is one mixture file and all cell reference files, then run the fragSizeFile process (see isoform vignette) on this file combination.

Outputs: fragSizeFile with suffix "_fraglens.txt" for the one mixture + all reference files combinations.

Note: Will need to run code in R in the command line

## Updated Process: Step 0

Step 0.1:

Thoughts: Need to run in command line (source the R file)

```{r}
library(asSeq)

intputDir = "where/.bam/files/are"
outputFolder = "Count/"
#------------------------------------------------------------------
# Generating BAM file List            
#------------------------------------------------------------------

#Set working directory to folder where BAM files are located:
setwd(inputDir)

#Generate initial list of files: (NOTE- .bam.bai files included)
init_list = list.files(pattern=".bam")

#Generate list of .bai files
int_list = list.files(pattern=".bai")

#Final List (excluding .bai files):
BAM_list = setdiff(init_list,int_list)

# -----------------------------------------------------------------
# check the bam files
# -----------------------------------------------------------------

#Checks length of BAM files to ensure all has run properly:
length(BAM_list)

#Displays BAM list as another check for errors:
BAM_list

bam2use = BAM_list

#Loop across all BAM files in the folder:
for(i in 1:length(BAM_list)){

  bami = bam2use[i]
  
  #Generates a name that can be used in the files by stripping 
  #off the .BAM extension:
  sami = substr(bam2use[i],start=1,stop=nchar(bam2use[i])-4)
  
  # ----------------------------------------------------------
  # counting
  # ----------------------------------------------------------
  ctF  = sprintf("%s/count_%s.txt", outputFolder,sami)
  cmd1 = sprintf("samtools view %s | wc -l >> %s\n", bam2use[i], ctF)
  system(cmd1)
  
  # ----------------------------------------------------------
  # sorting
  # ----------------------------------------------------------
  cmd2 = sprintf("samtools sort -n %s %s/%s_sorted_by_name", bam2use[i], outputFolder, sami)
  system(cmd2)
  bamF = sprintf("%s/%s_sorted_by_name.bam", outputFolder, sami)
  
  # ----------------------------------------------------------
  # getUnique and filtering
  # ----------------------------------------------------------
  prepareBAM(bamF, sprintf("%s/%s_sorted_by_name", outputFolder, sami), sortIt=FALSE)
  
  system(sprintf("rm %s", bamF))
  
  # ----------------------------------------------------------
  # counting again
  # ----------------------------------------------------------
  cmd3   = sprintf("samtools view %s/%s_sorted_by_name_uniq_filtered.bam | wc -l >> %s\n", outputFolder, sami, ctF)
  system(cmd3)
}

```

Step 0.2: Diagnostics only

Step 0.3:

Note: Run in command line (source the R code)

```{r}

# Input directory: has the "sorted_by_name_uniq_filtered.bam" files
inputDir = "original_inputDir/outputFolder"

#--------------------------------------------------------------------------------------
# ISOFORM Software Library Access
#--------------------------------------------------------------------------------------
library(isoform) 

#------------------------------------------------------------------------------------------------
# Set bedFile (once identified and downloaded)               
#------------------------------------------------------------------------------------------------
bedFile = "/netscr/drwilson/Reference_Annotations/Homo_sapiens/Homo_sapiens.GRCh37.66.nonoverlap.exon.bed"

#------------------------------------------------------------------------------------------------
# Set Working Directory
#------------------------------------------------------------------------------------------------
setwd(inputDir)

#------------------------------------------------------------------------------------------------
# Loop across all replicates and files:
#        For loop assumes that all files within a class (ECC1, HMEC, GM12878) have same bed File.
#------------------------------------------------------------------------------------------------

cmd  = "ls *_sorted_by_name_uniq_filtered.bam"
ffs  = system(cmd, intern=TRUE)
length(ffs)
head(ffs)
sams = gsub("_sorted_by_name_uniq_filtered.bam", "", ffs)

for(i in 1:length(ffs)){

  sam1 = sams[i]
  cat(i, sam1, date(), "\n")
  
  bamFile = ffs[i]
  outFile = sprintf("%s_counts.txt", sam1)
  
  countReads(bamFile, bedFile, outFile)
}
```

Step 0.4:

```{r}
#---------------------------------------------------------------------------------
# Set Working Directory [EDIT]
#---------------------------------------------------------------------------------

setwd("/netscr/drwilson/2015-06-19 Refined Half Simulate/Mixture Files/_counts/")

#---------------------------------------------------------------------------------
# Load/Organize Gene List into Matrix Form
#---------------------------------------------------------------------------------

load("/netscr/drwilson/Homo_sapiens.GRCh37.66.nTE.RData")
dim(nTE)
nTE[1:2,]
length(unique(nTE$geneId))

# Lists all count files in the current directory. Assigns number of such files
# to the idx2 random variable. To be used in looping.

ffs  = list.files(pattern="_counts.txt")
nn   = length(ffs)
ffs[1:2]
nn
idx2<-nn

# Creates matrix of following form:
#  -> One geneID per row
#  -> One Cell Line Sample per column
#  -> Count for gene i in sample j is cell value

# Labels rows by GeneID, labels columns (samples) by file name.

sams  = gsub("_counts.txt", "", ffs)
couts = matrix(0, nrow=nrow(nTE), ncol=(idx2-1+1))
colnames(couts) = sams[1:idx2]
rownames(couts) = nTE$geneId

#---------------------------------------------------------------------------------
# READ IN SAMPLE DATA:
#
# Reads in output from step 3 (countReads) and organizes it into a matrix form.
# Column 1: Read Count
# Column 2: Reference site (Transcript Cluster, Gene ID, Exons involved) 
#---------------------------------------------------------------------------------

for(idx in 1:idx2){
  
  cat(idx, date(), "\n")
  
  f1   = ffs[idx]
  dat  = scan(f1, what=character(0))  
  dat  = matrix(dat, ncol=2, byrow=TRUE);
 
  colNames = c("count", "exons")
  cN = sprintf("%s and %s", colNames[1], colNames[2])
 
# Error Checking: if a row does not have two columns, the procedure
# halts and warns the user.

  if(ncol(dat) != 2){
    stop(countFile, " should have 2 columns: ", cN, "\n")
  }
  
  colnames(dat) = colNames
  dim(dat)
  dat[1:2,]
  
#---------------------------------------------------------------------------------
# OBTAIN TRANSCRIPT CLUSTERS AND GENE IDS
#---------------------------------------------------------------------------------
  
# Splits each string from column 2 (reference sites) of the dat matrix into 3
# components: (i) Transcript cluster, (ii) Ensembl Gene ID, (iii) Exon Cluster.
# Output is a list of exon sets, one list for each line of original dat matrix.

  groupIDs = strsplit(dat[,"exons"], split=";|\\|", perl=TRUE)
  
# Creates function that will be used to extract the UNIQUE gene IDs from within
# each exon set.

  splitFun <- function(vx){
    unique(vx[grep("ENSG", vx)])
  }
  
#Extract unique geneIDs for each exon set read count.

  date()
  geneIDs = lapply(groupIDs, splitFun)
  date()
  geneIDs[1:2]
  
#---------------------------------------------------------------------------------
# DATA CHECKING:
#     This section assesses the number of unique gene IDs present for each exon 
# set/read count. If more than one unique geneID is present for an exon set,
# its reads are excluded. If only one geneID is present, these reads are assigned
# to that gene.
#---------------------------------------------------------------------------------
 
  ngIDs   = sapply(geneIDs, length)
  table(ngIDs)
  
  w2check = which(ngIDs > 1)
  
  chkGIDs <- function(g1){
    gkp    = ""
    ncombo = sum(!grepl(":", g1, fixed=TRUE))
    
    if(ncombo <= 1){
      g2s = strsplit(g1, split=":", fixed=TRUE)
      gus = unique(unlist(g2s))
      foundONE = FALSE
      
      for(gu1 in gus){
        if (all(grepl(gu1, g1))){
          if(foundONE){  
            gkp = ""
            break
          }else{
            foundONE = TRUE
            gkp = gu1
          }
        }
      }
    }
    
    gkp
  }

  gIDchk  = sapply(geneIDs[w2check], chkGIDs)
  length(gIDchk)
  gIDchk[1:4]
  
  geneIDs[w2check] = gIDchk
  n1      = length(geneIDs)
  geneIDs = unlist(geneIDs)
  if(n1 != length(geneIDs)){ stop("non-unique geneIDs\n") }
  
  gID2rm = w2check[which(gIDchk=="")]
  str1   = "combinations are skipped because they belong to different genes"
  message(length(gID2rm), " exon ", str1)
  
  dim(dat)
  if(length(gID2rm) > 0){
    dat     = dat[-gID2rm,]
    geneIDs = geneIDs[-gID2rm]
  }
  
  dim(dat)
  length(unique(geneIDs))
  
#---------------------------------------------------------------------------------
# RECORDING COUNTS:
#---------------------------------------------------------------------------------
 
# Converts counts from data matrix from character to numeric. Sums across all
# exon sets with the same, unique (after previous step), geneID.

  cts     = as.numeric(dat[,"count"])
  geneCts = tapply(cts, geneIDs, sum)
 
# Matches geneIDs from the geneCts matrix above with the nTE data set geneIDs
# for proper almagamation.
 
  mat1    = match(names(geneCts), nTE$geneId)
  wNotNA  = which(! is.na(mat1))
 
# Provides information on the number of geneIDs skipped during the process
# due to: (i) having two geneIDs present in read. 

  pp1 = round(sum(geneCts[-wNotNA])/sum(geneCts),4)
  nn1 = length(geneCts) - length(wNotNA)
  message(100*pp1, "% of reads @ ", nn1, " exon combinations are skipped\n")

# Updates original countmatrix with counts from the current sample passed through
# the for loop.

  couts[mat1[wNotNA],idx-1+1] = geneCts[wNotNA]
}

# Outputs a dataset with the gene counts matrix.

outF = sprintf("gene_counts_%d_%d.txt", 1, idx2)

write.table(couts, file = outF, append = FALSE, quote = FALSE, sep = "\t",
row.names = TRUE, col.names = TRUE)



```

Step 0.5 

```{r}
#-------------------------------------------------------------#
# Fragment Length Files: Generation                           #
#-------------------------------------------------------------#

# Specify Directory where read files are kept:
fragSizeDir = "bam_file_directory"
setwd(fragSizeDir)

# BAM Files where sequenced reads are located:
inputFiles = c("./Mixtures/merged/mf_CD4_0_CD8_100.bam",
               "./Mixtures/merged/mf_CD4_10_CD8_90.bam",
               "./Mixtures/merged/mf_CD4_20_CD8_80.bam",
               "./Mixtures/merged/mf_CD4_30_CD8_70.bam",
               "./Mixtures/merged/mf_CD4_40_CD8_60.bam",
               "./Mixtures/merged/mf_CD4_50_CD8_50.bam",
               "./Mixtures/merged/mf_CD4_60_CD8_40.bam",
               "./Mixtures/merged/mf_CD4_70_CD8_30.bam",
               "./Mixtures/merged/mf_CD4_80_CD8_20.bam",
               "./Mixtures/merged/mf_CD4_90_CD8_10.bam",
               "./Mixtures/merged/mf_CD4_100_CD8_0.bam",
               "./CD4/_count/SRR1550995_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD4/_count/SRR1551016_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD4/_count/SRR1551098_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD8/_count/SRR1551024_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD8/_count/SRR1551051_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD8/_count/SRR1551065_SBC_sorted_by_name_uniq_filtered.bam")

# Associated Labels for output files:
outputLabels = c("cd4_0_cd8_100",
                 "cd4_10_cd8_90",
                 "cd4_20_cd8_80",
                 "cd4_30_cd8_70",
                 "cd4_40_cd8_60",
                 "cd4_50_cd8_50",
                 "cd4_60_cd8_40",
                 "cd4_70_cd8_30",
                 "cd4_80_cd8_20",
                 "cd4_90_cd8_10",
                 "cd4_100_cd8_0",
                 "cd4_r1",
                 "cd4_r2",
                 "cd4_r3",
                 "cd8_r1",
                 "cd8_r2",
                 "cd8_r3")

# If any files are to be combined, list them in separate units:
comboList = list()
comboList[[1]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_0_cd8_100_lengths.txt")
comboList[[2]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_10_cd8_90_lengths.txt")
comboList[[3]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_20_cd8_80_lengths.txt")
comboList[[4]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_30_cd8_70_lengths.txt")
comboList[[5]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_40_cd8_60_lengths.txt")
comboList[[6]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_50_cd8_50_lengths.txt")
comboList[[7]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_60_cd8_40_lengths.txt")
comboList[[8]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_70_cd8_30_lengths.txt")
comboList[[9]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_80_cd8_20_lengths.txt")
comboList[[10]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_90_cd8_10_lengths.txt")
comboList[[11]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_100_cd8_0_lengths.txt")

# Combo Output Labels:
comboLabels = c("cd4_0_cd8_100",
                 "cd4_10_cd8_90",
                 "cd4_20_cd8_80",
                 "cd4_30_cd8_70",
                 "cd4_40_cd8_60",
                 "cd4_50_cd8_50",
                 "cd4_60_cd8_40",
                 "cd4_70_cd8_30",
                 "cd4_80_cd8_20",
                 "cd4_90_cd8_10",
                 "cd4_100_cd8_0")


fragLengths<-function(Input_Files,outputLabels,comboList,comboLabels,useCombo){
  outLabels = paste(outputLabels,"_lengths.txt",sep="")
  for(i in 1: length(Input_Files)){
    cmd1 = sprintf("samtools view -f 65 %s | awk '{print ($8>=$4) ? $8-$4+51 : $4-$8+51}' > %s",inputFiles[i],outLabels[i])
    system(cmd1)
  }
  
  if(missing(comboList) && useCombo==0){
    for(j in 1:length(outLabels)){
      cmd2_a = sprintf("cat %s | sort -n | uniq -c > %s_fraglens.txt",outLabels[j],outputLabels[j])
      system(cmd2_a)
    }
  } else if(useCombo==1 && missing(comboList)){
    stop("If you wish to combine files, you must list which files are to be combined!")
    
  } else { # comboList specified, and useCombo = 1
    
    ftc = unlist(lapply(X = comboList,FUN = function(x) {return(paste(x,collapse=" "))}))
    
    for(k in 1:length(comboList)){
      cmd2_b = sprintf("cat %s | sort -n | uniq -c > %s_fraglens.txt",ftc[k],comboLabels[k])
      system(cmd2_b)
    }
    
  }
}

fragLengths(Input_Files = inputFiles,outputLabels=outputLabels,comboList = comboList,comboLabels=comboLabels,useCombo=1)
```

## Original Process: GeneModel_Build and later

*Step 1*:  Mixture_Creation / GeneModel_Build.R 

Calls dev_compiles_geneMod() function from isoDeconv_geneModel_revised.R file

Inputs: 

Output: fit_geneMod object

Note: changed output of dev_compiles_geneMod() to be just an object, don't save an .RData object to some folder

*Step 2*:  Mixture_Creation / Restricting_Geneids_Pairwise.R

Establishes transcript clusters with highest levels of discriminatory capability

Library needed: biocLite.R library cummerbund

Inputs: "list_of_genes.txt" name annotation file, Cuffdiff_Out folder

Output: finalOut2 object as EnsembleIds2Use.RData object

*Step 3*:  Process_Real_Data / prepare_sigred.R

Inputs:  fin_geneMod object from *Step 1*, finalOut2 (EnsembleIds2Use.RData) object from *Step 2*

Output: sig_geneMod

*Step 4*:  Mixture_Creation / RecharacterizedOutput.R

Input: The sig_geneMod object from Step 3

Output:  Slightly modified version of sig_geneMod object

*Step 5*: Run pure sample production functions

Input: The modified sig_geneMod object from Step 4

Ouput: tmp.data = output from Pure.apply.fun() function from pure sample production functions file.

## Updated Process: GeneModel_Build.R and later

Step 1:

Note: need to generalize to multiple files (multiple combinations of one mixture and all cell type references)

```{r}
# Required Libraries:
library(gtools)
library(IsoDeconvMM)

# Inputs
file = "g10h90" # Should be one of the comboLabels provided in FragLengths_Function_mixture.R

sys_statement1 = sprintf("countData=c(\"mf_%s_counts.txt\",
                         \"CD4_SRR1550995_SBC_counts.txt\",
                         \"CD4_SRR1551016_SBC_counts.txt\",
                         \"CD4_SRR1551098_SBC_counts.txt\",
                         \"CD8_SRR1551024_SBC_counts.txt\",
                         \"CD8_SRR1551051_SBC_counts.txt\",
                         \"CD8_SRR1551065_SBC_counts.txt\")",file)
eval(parse(text=sys_statement1))
labels = c("mix","CD4_ref1","CD4_ref2","CD4_ref3",
           "CD8_ref1","CD8_ref2","CD8_ref3")
cellTypes = c("mix","CD4","CD4","CD4",
              "CD8","CD8","CD8")
fragSizeFile = sprintf("/netscr/drwilson/2018-04-05 Paper 1/Frag_Lengths/%s_fraglens.txt",file)
bedFile = "/netscr/drwilson/Reference_Annotations/Homo_sapiens/Homo_sapiens.GRCh37.66.nonoverlap.exon.bed"
knownIsoforms = "/netscr/drwilson/Reference_Annotations/Homo_sapiens/Homo_sapiens.GRCh37.66.nonoverlap.exon.knownIsoforms.RData"
readLen=50
lmax=600
eLenMin=1

```

Suppose the above process has been generalized to multiple files

```{r}
files = file

final_geneMod = list()

for(j in 1:length(files)){
  # Call dev_compiled_geneMod function
  fin_geneMod = dev_compiled_geneMod(countData=countData,labels = labels,total_cts = total_cts, 
                       cellTypes=cellTypes, bedFile=bedFile,knownIsoforms=knownIsoforms,
                       fragSizeFile=fragSizeFile,output=output,readLen=readLen,lmax=lmax,
                       eLenMin=eLenMin)
  final_geneMod[[j]] = fin_geneMod
}

```


Step 2:

```{r}
#-----------------------------------------------------------------------------#
# ESTABLISHING CLUSTERS WITH HIGHEST LEVELS OF DISCRIMINATORY CAPABILITY      #
#-----------------------------------------------------------------------------#
#------------------ LOAD AND PROCESS GENE NAMES -------------------#
anno_names = read.table(file = "D:/DougData/Documents/Genomics Training Grant/Update_12_10_2014/FINAL/Article/list_of_genes.txt",header = TRUE,sep = ",")
anno_names$gene_short_name = anno_names$Associated.Gene.Name

#------------------ CALL THE LIBRARY ------------------#
source("https://bioconductor.org/biocLite.R")
biocLite("cummeRbund")
library(cummeRbund)

# Had to downgrade to RSQ-lite v 1.1-2

finalOut2 = EnsemblIds2Use(folder = "Cuffdiff_Out",
                            directory = "D:/DougData/Documents/Dissertation/Paper 1 - Cell Type Abundance Estimation/Daily Work/1_30_2018/")

```

Step 3:

```{r}
setwd("/netscr/drwilson/2018-04-05 Paper 1/MappedData/Real_Data_Opt/GeneModels/")

analy_genes = finalOut2$Ensembl.ID

significant_geneMod = list()

for(j in 1:length(final_geneMod)){

  fin_geneMod = final_geneMod[[j]]
  
  indices2chk = which(names(fin_geneMod)!="Sample_Info")
  indices_tmp = NULL
  indices=NULL
  indices_tmp = rep(0,length(geneMod)) # What is this geneMod object?
  for(i in indices2chk){
    infodf = fin_geneMod[[i]]$info
    genesi = unique(infodf$gene)
    genesi = unique(unlist(strsplit(x=genesi,split = ":")))
    if(any(genesi %in% analy_genes)){indices_tmp[i]=1}
  }
  indices = which(indices_tmp==1)
  
  sig_geneMod = fin_geneMod[indices]
  sig_geneMod["Sample_Info"] = fin_geneMod["Sample_Info"]
  
  sig_geneMod = rem_clust(geneMod = sig_geneMod,co = 5,min_ind = 0)
  
  # message("File: ",file_labels[j]," // nGenes= ",length(sig_geneMod))
  # 
  # save(sig_geneMod,file=file_labels[j])
  
  significant_geneMod[[j]] = sig_geneMod
}
```

Step 4:

```{r}

library(gtools)

#-------------------------------------------------------------------#
# EDIT TO GROUP CELL TYPES                                          #
#-------------------------------------------------------------------#

modified_sig_geneMod = list()

for(f in 1:length(significant_geneMod)){
  
  sig_geneMod = significant_geneMod[[f]]
  
  info_mat = sig_geneMod[["Sample_Info"]]
  cellTypes = unique(info_mat$Cell_Type)
  
  ctList = list()
  
  for(j in 1:length(cellTypes)){
    idx = which(info_mat$Cell_Type==cellTypes[j])
    ctList[[cellTypes[j]]] = list(samps = info_mat$Label[idx], tots = info_mat$Total[idx])
  }
  
  idx2consider = which(names(sig_geneMod)!="Sample_Info")
  for(k in idx2consider){
    for(l in 1:length(cellTypes)){
      samps2use = ctList[[l]]$samps
      tots      = ctList[[l]]$tots
  
      y_vecs  = paste("sig_geneMod[[k]]$y",samps2use,sep = "_")
      y_vecsc = paste(y_vecs,collapse = ",")
      nExon = eval(parse(text=sprintf("length(%s)",y_vecs[1])))
      textcmd = sprintf("matrix(c(%s),nrow=nExon,ncol=length(samps2use))",y_vecsc)
      expMat  = eval(parse(text=textcmd))
  
      totmg   = tots-colSums(expMat)
      expMat2 = rbind(totmg,expMat)
  
      if(cellTypes[l]!="mix"){
        sig_geneMod[[k]][[cellTypes[l]]] = list(cellType=cellTypes[l],rds_exons=expMat2)
      } else {
        sig_geneMod[[k]][[cellTypes[l]]] = list(cellType=cellTypes[l],rds_exons_t=expMat2)
      }
      
    }
  }
  
  modified_sig_geneMod[[f]] = sig_geneMod
  # save(sig_geneMod,file=sprintf("rechar_%s_geneMod.RData",file))
}

```

Step 5:

Note: Confused about what files are used here

```{r}
# Call_Model / Revised_Sim_PS_codeNew.R code process

library(gtools)
library(alabama)

#-----------------------------------------------------------#
# CALL Pure Sample                                          #
#-----------------------------------------------------------#
cellTypes = c("cd4","cd8")

pure_est = list()

for(j in 1:length(modified_sig_geneMod)){
  
  sig_geneMod = modified_sig_geneMod[[j]]
  
  sim.out = sig_geneMod[which(names(sig_geneMod)!="Sample_Info")]

  # Clusters with single isoforms:
  # EXCLUDE THEM FOR THE MOMENT!.
  dim_mat = matrix(0,nrow=length(sim.out),ncol=2)
  excl_clust = c()
  excl_clust2 = c()
  for(i in 1:length(sim.out)){
    dim_mat[i,] = dim(sim.out[[i]][["X"]])
    if(all(dim_mat[i,]==c(1,1))){
      excl_clust = c(excl_clust,i)
    }
    if(dim_mat[i,2] == 1){
      excl_clust2 = c(excl_clust2,i)
    }
  }
  
  excl_clust_union = union(excl_clust,excl_clust2)
  if(length(excl_clust_union)>0){
    sim.new = sim.out[-c(excl_clust_union)]
  } else {
    sim.new = sim.out
  }
  
  
  # Optimize the Pure Sample Functions:
  tmp.data = Pure.apply.fun(data.list = sim.new, cellTypes = cellTypes, corr_co = 1)
  
  # save_cmd = sprintf("save(tmp.data,file=\"../Compiled_Output/%s_pure_est.RData\")",file)
  # eval(parse(text=save_cmd))
  
  pure_est[[j]] = tmp.data
  
  # message("Sample ",file,"Completed")
    
}



```

Step 6:

Multiple Cluster code: (Revised_Sim_Mix_Calls_MI.R)

Calls Single Cluster code: (Revised_Sim_MixCode_SI.R)

```{r}

library(alabama)

IsoDeconv_Output = list()

for(i in 1:length(pure_est)){
  
  tmp.data = pure_est[[i]]
  
  #--------------------------------------------------------#
  # Establish input break ups                              #
  #--------------------------------------------------------#
  # Cell-Types:
  cellTypes = c("cd4","cd8")
  
  # Data Set Necessities:
  clust.start = 1
  clust.end = length(tmp.data)
  by.value = 15
  
  start.pts = seq(from = 1,to = clust.end,by = by.value)
  end.pts = c((start.pts[-1]-1),clust.end)
  
  cluster_output = list()
  for(m in 1:length(start.pts)){
    
    # Call Revised_Sim_MixCode_SI.R code
    curr.clust.opt = tmp.data[c(start.pt:end.pt)]
    curr.clust.out = STG.Update_Cluster.All(all_data=curr.clust.opt, cellTypes = cellTypes,
                                            optimType="nlminb", simple.Init=FALSE, initPts=c(0.5))
    
    cluster_output[[m]] = curr.clust.out
  }
  
  IsoDeconv_Output[[i]] = cluster_output
}

```


## Edit of Updated Process

Note: Once I'm confident the "Updated Process" steps above work as expected, I will modularize some steps (create some additional functions). Ideally, it would be nice to have just one "wrapper" function where all of the inputs go and one output.

The End
